{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawler and Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of this page is almost copied and pasted from this [article](https://github.com/TianYe00/2015lab2/blob/master/Lab2.ipynb). The second part is one application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving data from the web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the environment namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.core.display import HTML\n",
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the appropriately named get function to issue a GET request. This is equivalent to typing a URL into your browser and hitting enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the HU Wikipedia page\n",
    "req = requests.get(\"https://en.wikipedia.org/wiki/Harvard_University\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to assign the value of the text property of this Request object to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page = req.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the text of the HU Wikipedia page. But this mess of HTML tags would be a pain to parse manually. Which is why we will use another very cool Python library called BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problems with HTML is that over the years browsers have evolved to be very forgiving of \"malformed\" syntax. Your browser is smart enough to detect some common problems, such as open tags, and correct them on the fly.\n",
    "\n",
    "Unfortunately, we do not have the time or patience to implement all the different corner cases, so we'll let BeautifulSoup do that for us.\n",
    "\n",
    "BeautifulSoup can deal with HTML or XML data, so the next line parser the contents of the page variable using its HTML parser, and assigns the result of that to the soup variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup obkects have a cool little method that allows you to see the HTML content in a nice, indented way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now reference elements of the HTML document in different ways. One very convenient way is by using the dot notation, which allows us to access the elements as if they were properties of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Harvard University - Wikipedia, the free encyclopedia</title>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we should make it clear that this is again just syntactic sugar. title is not a property of the soup object and I can prove it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"title\" in dir(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nice for HTML elements that only appear once per page, such the the title tag. But what about elements that can appear multiple times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p><b>Harvard University</b> is a private <a class=\"mw-redirect\" href=\"/wiki/Research_university\" title=\"Research university\">research university</a> in <a href=\"/wiki/Cambridge,_Massachusetts\" title=\"Cambridge, Massachusetts\">Cambridge, Massachusetts</a> (US), established 1636, whose history, influence and wealth have made it one of the world's most prestigious universities.<sup class=\"reference\" id=\"cite_ref-6\"><a href=\"#cite_note-6\">[6]</a></sup><sup class=\"reference\" id=\"cite_ref-7\"><a href=\"#cite_note-7\">[7]</a></sup><sup class=\"reference\" id=\"cite_ref-:0_8-0\"><a href=\"#cite_note-:0-8\">[8]</a></sup><sup class=\"reference\" id=\"cite_ref-9\"><a href=\"#cite_note-9\">[9]</a></sup><sup class=\"reference\" id=\"cite_ref-10\"><a href=\"#cite_note-10\">[10]</a></sup><sup class=\"reference\" id=\"cite_ref-11\"><a href=\"#cite_note-11\">[11]</a></sup></p>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Be careful with elements that show up multiple times.\n",
    "soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all(\"p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the Wikipedia page on your browser, you'll notice that it has a couple of tables in it. We will be working with the \"Demographics\" table, but first we need to find it.\n",
    "\n",
    "One of the HTML attributes that will be very useful to us is the \"class\" attribute.\n",
    "\n",
    "Getting the class of a single element is easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['infobox', 'vcard']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.table[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List Comprehensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will use a list comprehension to see all the tables that have a \"class\" attributes. List comprehensions are a very cool Python feature that allows for a loop iteration and a list creation in a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'infobox', u'vcard'],\n",
       " [u'toccolours'],\n",
       " [u'metadata', u'plainlinks', u'ambox', u'mbox-small-left', u'ambox-content'],\n",
       " [u'infobox', u'vcard'],\n",
       " [u'wikitable'],\n",
       " [u'metadata', u'plainlinks', u'mbox-small'],\n",
       " [u'navbox'],\n",
       " [u'nowraplinks', u'collapsible', u'collapsed', u'navbox-inner'],\n",
       " [u'nowraplinks', u'navbox-subgroup'],\n",
       " [u'nowraplinks', u'navbox-subgroup'],\n",
       " [u'navbox'],\n",
       " [u'nowraplinks', u'collapsible', u'collapsed', u'navbox-inner'],\n",
       " [u'navbox'],\n",
       " [u'nowraplinks', u'collapsible', u'autocollapse', u'navbox-inner'],\n",
       " [u'navbox'],\n",
       " [u'nowraplinks', u'collapsible', u'autocollapse', u'navbox-inner'],\n",
       " [u'navbox'],\n",
       " [u'nowraplinks', u'collapsible', u'autocollapse', u'navbox-inner'],\n",
       " [u'navbox'],\n",
       " [u'nowraplinks', u'collapsible', u'autocollapse', u'navbox-inner'],\n",
       " [u'navbox'],\n",
       " [u'nowraplinks', u'collapsible', u'autocollapse', u'navbox-inner'],\n",
       " [u'navbox'],\n",
       " [u'nowraplinks', u'collapsible', u'autocollapse', u'navbox-inner'],\n",
       " [u'navbox'],\n",
       " [u'nowraplinks', u'hlist', u'collapsible', u'autocollapse', u'navbox-inner'],\n",
       " [u'navbox'],\n",
       " [u'nowraplinks', u'collapsible', u'autocollapse', u'navbox-inner'],\n",
       " [u'navbox'],\n",
       " [u'nowraplinks', u'collapsible', u'autocollapse', u'navbox-inner'],\n",
       " [u'navbox'],\n",
       " [u'nowraplinks', u'hlist', u'collapsible', u'autocollapse', u'navbox-inner'],\n",
       " [u'navbox'],\n",
       " [u'nowraplinks', u'hlist', u'navbox-inner']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t[\"class\"] for t in soup.find_all(\"table\") if t.get(\"class\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned, we will be using the Demographics table for this lab. The next cell contains the HTML elements of said table. We will render it in different parts of the notebook to make it easier to follow along the parsing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"wikitable\" style=\"text-align:center; float:left; font-size:85%; margin-right:2em;\">\n",
       "<caption><i>Demographics of student body</i><sup class=\"reference\" id=\"cite_ref-Head_count_116-0\"><a href=\"#cite_note-Head_count-116\">[116]</a></sup><sup class=\"reference\" id=\"cite_ref-117\"><a href=\"#cite_note-117\">[117]</a></sup><sup class=\"reference\" id=\"cite_ref-118\"><a href=\"#cite_note-118\">[118]</a></sup></caption>\n",
       "<tr>\n",
       "<th></th>\n",
       "<th>Undergraduate</th>\n",
       "<th>Graduate<br/>\n",
       "and Professional</th>\n",
       "<th>U.S. Census</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<th>Asian/Pacific Islander</th>\n",
       "<td>17%</td>\n",
       "<td>11%</td>\n",
       "<td>5%</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<th>Black/Non-Hispanic</th>\n",
       "<td>6%</td>\n",
       "<td>4%</td>\n",
       "<td>12%</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<th>Hispanics of any race</th>\n",
       "<td>9%</td>\n",
       "<td>5%</td>\n",
       "<td>16%</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<th>White/non-Hispanic</th>\n",
       "<td>46%</td>\n",
       "<td>43%</td>\n",
       "<td>64%</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<th>Mixed Race/Other</th>\n",
       "<td>10%</td>\n",
       "<td>8%</td>\n",
       "<td>9%</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<th>International students</th>\n",
       "<td>11%</td>\n",
       "<td>27%</td>\n",
       "<td>N/A</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_html = str(soup.find(\"table\", \"wikitable\"))\n",
    "HTML(table_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll use a list comprehension to extract the rows (`tr`) elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr>\n",
       " <th></th>\n",
       " <th>Undergraduate</th>\n",
       " <th>Graduate<br/>\n",
       " and Professional</th>\n",
       " <th>U.S. Census</th>\n",
       " </tr>, <tr>\n",
       " <th>Asian/Pacific Islander</th>\n",
       " <td>17%</td>\n",
       " <td>11%</td>\n",
       " <td>5%</td>\n",
       " </tr>, <tr>\n",
       " <th>Black/Non-Hispanic</th>\n",
       " <td>6%</td>\n",
       " <td>4%</td>\n",
       " <td>12%</td>\n",
       " </tr>, <tr>\n",
       " <th>Hispanics of any race</th>\n",
       " <td>9%</td>\n",
       " <td>5%</td>\n",
       " <td>16%</td>\n",
       " </tr>, <tr>\n",
       " <th>White/non-Hispanic</th>\n",
       " <td>46%</td>\n",
       " <td>43%</td>\n",
       " <td>64%</td>\n",
       " </tr>, <tr>\n",
       " <th>Mixed Race/Other</th>\n",
       " <td>10%</td>\n",
       " <td>8%</td>\n",
       " <td>9%</td>\n",
       " </tr>, <tr>\n",
       " <th>International students</th>\n",
       " <td>11%</td>\n",
       " <td>27%</td>\n",
       " <td>N/A</td>\n",
       " </tr>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = [row for row in soup.find(\"table\", \"wikitable\").find_all(\"tr\")]\n",
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then use a lambda expression to replace new line characters with spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lambda expressions return the value of the expression inside it.\n",
    "# In this case, it will return a string with new line characters replaced by spaces.\n",
    "rem_nl = lambda s: s.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we extract the text value of the columns. If you look at the table above, you'll see that we have three columns and six rows.\n",
    "\n",
    "Here we're taking the first element (Python indexes start at zero), iterating over the th elements inside it, and taking the text value of those elements. We should end up with a list of column names.\n",
    "But there is one little caveat: the first column of the table is actually an empty string (look at the cell right above the row names). We could add it to our list and then remove it afterwards; but instead we will use the if statement inside the list comprehension to filter that out.\n",
    "\n",
    "You should be familiar with if statements. They perform a Boolean test and an action if the test was successful. Python considers most values to be equivalent to True. The exceptions are `False, None, 0, \"\"` (empty string), `[]/{}/(,)`... (empty containers). Here the get_text will return an empty string for the first cell of the table, which means that the test will fail and the value will not be added to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Undergraduate', u'Graduate and Professional', u'U.S. Census']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [rem_nl(col.get_text()) for col in rows[0].find_all(\"th\") if col.get_text()]\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same for the rows. Notice that since we have already parsed the header row, we will continue from the second row. The `[1:]` is a slice notation and in this case it means we want all values starting from the second position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Asian/Pacific Islander',\n",
       " u'Black/Non-Hispanic',\n",
       " u'Hispanics of any race',\n",
       " u'White/non-Hispanic',\n",
       " u'Mixed Race/Other',\n",
       " u'International students']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = [row.find(\"th\").get_text() for row in rows[1:]]\n",
    "indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have another lambda expression that transforms the string on the cells to integers. We start by checking if the last character of the string (Python allows for negative indexes) is a percent sign. If that is true, then we convert the characters before the sign to integers. Lastly, if one of the prior checks fails, we return a value of None.\n",
    "\n",
    "This is a very common pattern in Python, and it works for two reasons: Python's and and or are \"short-circuit\" operators. This means that if the first element of an and statement evaluates to False, the second one is never computed (which in this case would be a problem since we can't convert a non-digit string to an integer). The or statement works the other way: if the first element evaluates to True, the second is never computed.\n",
    "The second reason this works is because these operators will return the value of the last expression that was evaluated, which is this case will be either the integer value or the value None.\n",
    "\n",
    "One last thing to notice: Python slices are open on the upper bound. So the `[:-1]` construct will return all elements of the string, except for the last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_num = lambda s: s[-1] == \"%\" and int(s[:-1]) or None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the lambda expression to parse the table values.\n",
    "\n",
    "Notice that we have two for ... in ... in this list comprehension. That is perfectly valid and somewhat common. Although there is no real limit to how many iterations you can perform at once, having more than two can be visually unpleasant, at which point regular nested loops might be a better solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 11, 5, 6, 4, 12, 9, 5, 16, 46, 43, 64, 10, 8, 9, 11, 27, None]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [to_num(value.get_text()) for row in rows[1:] for value in row.find_all(\"td\")]\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with the list above is that the values lost their grouping.\n",
    "\n",
    "The zip function is used to combine two sequences element wise. So zip([1,2,3], [4,5,6]) would return [(1, 4), (2, 5), (3, 6)].\n",
    "\n",
    "This is the first time we see a container bounded by parenthesis. This is a tuple, which you can think of as an immutable list (meaning you can't add, remove, or change elements from it). Otherwise they work just like lists and can be indexed, sliced, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17, 11, 5), (6, 4, 12), (9, 5, 16), (46, 43, 64), (10, 8, 9), (11, 27, None)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_values = zip(*[values[i::3] for i in range(len(columns))])\n",
    "stacked_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Undergraduate</th>\n",
       "      <th>Graduate and Professional</th>\n",
       "      <th>U.S. Census</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asian/Pacific Islander</th>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black/Non-Hispanic</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanics of any race</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White/non-Hispanic</th>\n",
       "      <td>46</td>\n",
       "      <td>43</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixed Race/Other</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International students</th>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Undergraduate  Graduate and Professional  U.S. Census\n",
       "Asian/Pacific Islander             17                         11            5\n",
       "Black/Non-Hispanic                  6                          4           12\n",
       "Hispanics of any race               9                          5           16\n",
       "White/non-Hispanic                 46                         43           64\n",
       "Mixed Race/Other                   10                          8            9\n",
       "International students             11                         27          NaN"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(stacked_values, columns=columns, index=indexes)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stacked_by_col = [values[i::3] for i in range(len(columns))]\n",
    "df = pd.DataFrame(stacked_by_col).T\n",
    "df.columns = columns\n",
    "df.index = indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dicts = [{col: val for col, val in zip(columns, col_values)} for col_values in stacked_values]\n",
    "df = pd.DataFrame(data_dicts, index=indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hand-on application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are required to find info from [web page](http://www.seas.upenn.edu/directory/departments.php), extract the information from it, crawl to the profile page of each person (eg. http://www.seas.upenn.edu/directory/profile.php?ID=191), and extract more information. \n",
    "By using chrome, right-click->View Page Source will lead you to the HTML file page. Use online html [formatter](http://www.cleancss.com/html-beautify/) and you will get a much prettier view of the html file. In case you don’t understand HTML syntax, we will explain it in an illustrative way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "req = requests.get('http://www.seas.upenn.edu/directory/departments.php')\n",
    "page = req.text\n",
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"700\"><tr><td><h2><br/></h2></td></tr></table>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_html = soup.find_all('table')\n",
    "table_html2 = table_html.find_next('table')\n",
    "HTML(str(table_html2))\n",
    "tt = soup.find_all('table')\n",
    "len(tt)\n",
    "tt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_html = soup.find_all('table')\n",
    "rem_nl = lambda s: s.replace(\": \", \"\")  #Delete the ': ' in the colums\n",
    "rem_nl1 = lambda s: s.replace(\"\\xa0\", \" \")   #This is to replace \"\\xa\" with \" \".ß\n",
    "columns = [rem_nl(col.get_text()) for col in table_html[3].find_all(\"strong\") if col.get_text()]\n",
    "columns.append('Email')\n",
    "table_out = DataFrame(index=range(int(489/3)), columns = columns)\n",
    "for i in range(1, (len(table_html) - 1)/3):\n",
    "    rr = tt[3 * i].find_all('tr')\n",
    "    table_out.ix[i - 1, 0] = rem_nl1(rr[0].get_text().lstrip('\\xa0Name: ').rstrip('|  View Profile')) \n",
    "    rr1 = rr[1].get_text()\n",
    "    rr1_t = np.array(list(rr1))\n",
    "    ind_f = np.arange(len(rr1))[rr1_t == '(']\n",
    "    if len(ind_f) != 0:\n",
    "        ind_b = np.arange(len(rr1))[rr1_t == ')']\n",
    "        for a in range(len(ind_f)):\n",
    "            if a == 0:\n",
    "                table_out.ix[i - 1, 1] = rr1[(ind_f[a] + 1):ind_b[a]]\n",
    "            else:\n",
    "                table_out.ix[i - 1, 1] = table_out.ix[i - 1, 1] + ' | ' + rr1[(ind_f[a] + 1):ind_b[a]]\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-56-7d99a0d13d83>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-56-7d99a0d13d83>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    guess = input('Guess one integer between 0 and 100 (inclusive): ')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "secret_number = randint(0,100)\n",
    "guess = -1\n",
    "num_guess = 0\n",
    "while (secret_number != guess) & (num_guess <= 10): \n",
    "    guess = input('Guess one integer between 0 and 100 (inclusive): ')\n",
    "    if type(guess) != int:\n",
    "        print('Your guess is not an integer.')\n",
    "        guess = input('Guess one integer between 0 and 100 (inclusive): ')\n",
    "    if guess < 0 | guess > 100:\n",
    "        print('Your guess is out of range.')\n",
    "         guess = input('Guess one integer between 0 and 100 (inclusive): ')\n",
    "    if guess < secret_number:\n",
    "        print('Your guess is low.')\n",
    "    elif guess > secret_number:\n",
    "        print('Your guess is high.')\n",
    "    else:\n",
    "        print('You guess right!')\n",
    "    num_guess += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
